{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8070f263",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "## Outline\n",
    "1. What is Supervised Learning\n",
    "2. Classification vs. Regression\n",
    "3. What is Linear Regression \n",
    "4. Cost/Loss Function\n",
    "5. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb9e2b7",
   "metadata": {},
   "source": [
    "# 1. Supervised Learning\n",
    "\n",
    "At the training time we are presented with both the inputs and outputs, and our goal is to make a model that predicts outputs based on the inputs (for the unseen/future data). So we learn parameters for the models to improve our prediction score (or rather reduce the error in our predictions) based on the training data.\n",
    "\n",
    "### The assumptions (not requirements, we just simplify the difficulty of modelling the) of supervised learning algorithms: \n",
    "* IID (Independent and Identically Distributed) data (X, y).\n",
    "The conditional probability can be modeled by p(y_i | X_i) and\n",
    "1. Identical: p(y_i | X_i) is the same for all samples \n",
    "2. Independent: X_i is independent from X_j and the same is true for y_i and y_j\n",
    "\n",
    "* Naive Bayes: Each feature is independent from each other\n",
    "\n",
    "\\* But sometimes there are outliers which need to be handled.\n",
    "\n",
    "Notation Info: <br>\n",
    "    &emsp; A sample i is X_i and y_i. Where X_i is the input and y_i is the output. <br>\n",
    "    &emsp; Model's prediction for sample i is y_hat_i."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db18f867",
   "metadata": {},
   "source": [
    "# 2. Classification vs. Regression\n",
    "\n",
    "There are two main categories of Supervised Learning algorithms: Classification and Regression.\n",
    "\n",
    "Examples of Classification problems: bird species classification using recordings of their screeches, dog breed classification from the pictures, etc.\n",
    "\n",
    "Examples of Regression problems: house price prediction given number of rooms, latitude and longitude prediction given camera taken images, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5887f39e",
   "metadata": {},
   "source": [
    "# 3. What is Linear Regression\n",
    "        Linear Regression is a model that predicts the output(y) as a linear combination of the inputs (x).\n",
    "        y_i = theta * x_i \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752eb00e",
   "metadata": {},
   "source": [
    "# 4. Cost/Loss Function\n",
    "A cost function is a function which quantifies the amount of error between the expected result and the model's predicted output. \n",
    "A cost function frequently used in linear regression is squared error. \n",
    "\n",
    "sum(squared(theta_T * x_i - y_i)), the sum is done over i=1 to i=n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b451e14",
   "metadata": {},
   "source": [
    "# 5. Gradient Descent\n",
    "theta = theta - alpha * gradient\n",
    "\n",
    "Our objective is to minimize the loss function. Which means argmin(J(theta, x, y)). If we take the derivative of the loss function with respect to theta (since x and y are not parameters of the model), we will get a direction which points in the increasing direction of the loss. Which is why we update the theta with a negative multiple of gradient. Alpha is learning rate which controls how fast we step after each update. And we are trying to minimize the gradient since that is the minima/maxima of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af82db",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "I came to a conclusion to have my notes on my notebook and maybe, a huge maybe. Have them concisely and everything and later convert them to a latex if I really want to."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
